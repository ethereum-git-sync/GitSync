{
  "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
  "repository_url": "https://api.github.com/repos/ethereum/go-ethereum",
  "labels_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704/comments",
  "events_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704/events",
  "html_url": "https://github.com/ethereum/go-ethereum/issues/15704",
  "id": 283014412,
  "node_id": "MDU6SXNzdWUyODMwMTQ0MTI=",
  "number": 15704,
  "title": "NTFS file system improvements (suggestions)",
  "user": {
    "login": "mariushudea",
    "id": 34661103,
    "node_id": "MDQ6VXNlcjM0NjYxMTAz",
    "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/mariushudea",
    "html_url": "https://github.com/mariushudea",
    "followers_url": "https://api.github.com/users/mariushudea/followers",
    "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
    "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
    "organizations_url": "https://api.github.com/users/mariushudea/orgs",
    "repos_url": "https://api.github.com/users/mariushudea/repos",
    "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
    "received_events_url": "https://api.github.com/users/mariushudea/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1132689577,
      "node_id": "MDU6TGFiZWwxMTMyNjg5NTc3",
      "url": "https://api.github.com/repos/ethereum/go-ethereum/labels/status:triage",
      "name": "status:triage",
      "color": "6be514",
      "default": false,
      "description": ""
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 12,
  "created_at": "2017-12-18T20:45:16Z",
  "updated_at": "2019-08-27T08:51:03Z",
  "closed_at": "2019-08-27T08:51:03Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "1. Reduce number of files per folder \r\n\r\nEthereum likes to create tens of thousands of 2 MB  LDB files in the chaindata folder.  \r\nThis can be a problem on NTFS file systems (Windows) which can have a degraded performance when more than 1000 or so files are within a folder.  Once the number of files goes above such threshold, the access times increase and other problems appear (fragmentation of indexes and others) \r\n\r\nI'd like to suggest creating a \"folder tree\" of some sort and storing these tables in such a way so that they's only around 1000 files or so in each folder.\r\n\r\nA suggestion would be :  [  1'000'000 ] /  [  1'000 ] / [ number ]. LDB\r\n```\r\n  000073.ldb :     0/0/000073.ldb\r\n  943185.ldb :    0/94/943185.ldb\r\n 1234567.ldb :  0/123/1234567.ldb\r\n87654321.ldb : 8/765/87654321.ldb\r\n```\r\n\r\nThis can be backwards compatible in case user simply updates geth and leaves old database intact. Geth could try to open the file with the new path structure and if it's not found, it could try to access it using the old location and it would auto-magically work. \r\nAlternatively, at startup, geth could try to scan the chaindata folder and build a list of *.LDB file names in memory and auto correct paths as needed, or maybe even create folders and move them to their folders automatically unless they're locked (maybe geth already running?) or read only?\r\n\r\n2. Attempt to reduce file fragmentation by pre-filling files with empty data as they're created\r\n\r\nThis is probably LevelDB related and not sure if it's even possible, but I wonder if it would be possible to reduce file fragmentation in the LDB files by tweaking the file write code so that when created, the LDB files will have some amount of bytes pre-allocated (thinking something like 128-512 KB). \r\nJust tested on a Windows 2008 based dedicated server, even on a freshly defragmented partition, the freshly created LDB files have between 5 and 40 fragments and being so many in a folder further slows down everything. \r\n\r\nMost LDB files are only around 2 MB so I'm thinking as geth loads the data it wouldn't be a big deal if each file reserves up to 512 KB of disk space. Worst case scenario, you get maybe 10-20% extra disk space used by the files, maybe a couple of GB when the whole thing uses tens of GB (wouldn't be a big deal)\r\n\r\nquoting from another forum thread on reducing fragmentation caused by 7zip when extracting files, this was suggested :\r\n\r\n \r\n\r\n> On Windows using the Win32 API this would look something like this (without any error checking):\r\n> HANDLE hFile;\r\n> LARGE_INTEGER liSize;\r\n> hFile = CreateFile(\"somelargefile.bin\", GENERIC_WRITE, FILE_SHARE_READ, 0, CREATE_NEW, FILE_FLAG_SEQUENTIAL_SCAN, 0);\r\n> liSize.LowPart = 1234567890;\r\n> liSize.HighPart = 0;\r\n> SetFilePointerEx(hFile, liSize , NULL, FILE_BEGIN);\r\n> SetEndOfFile(hFile);\r\n> SetFilePointer(hFile, 0, NULL, FILE_BEGIN);\r\n> \r\n> The SetEndOfFile call is were it all happens in the OS.\r\n> On NTFS this call performs very fast and still pre-allocates the full physical disk space for the file (look up doc for SetEndOfFile and how it works together with SetFileValidData to avoid the need to zero-fill the complete file which would slow down things).\r\n> \r\n\r\nIt should be possible to go even further for example and store these LDB files in larger files, like a TAR archive for example or another format that has super simple structure. \r\nTAR for example is super basic ,  512 bytes for the file name and metadata, then file contents in 512 byte chunks (pad with null characters if the file size is not exactly divisible by 512), then repeat and the end of file is represented by 1024 bytes of empty data\r\n\r\nSo you could create such a TAR file and at creation allocate let's say 100-500 MB in advance and create file records inside the TAR file:\r\n\r\n[ File 1 Header  (512 bytes) ] [  File 1 Content 10KB ]  \r\n[ Padding 1  Header  (512 bytes) ] [ Padding 1 Content 501 KB ] =  10.5 KB used by file and 501.5 KB of \r\n\r\n[  File 2 Header  (512 bytes) ] [  File 2 Content 65 KB ]  \r\n[ Padding 1  Header  (512 bytes) ] [ Padding 1 Content 446 KB ]\r\n\r\n[ end of tar file, 1024 bytes of nothing]\r\n\r\nAs you write data into 1.ldb increasing its size, you simply write over the 512 byte header block for the padding file and then recreate the padding file header further down in your 512 KB block and update the padding amount to match the available space.\r\nIf the file gets close to 512 KB, you can just take the file contents and append it to the end of the TAR file and empty the whole 512 KB block of space making it available for another LDB file (when it will eventually be created)\r\nYou  would only have to store in memory the offset where each LDB file is stored inside each tar file. \r\nOnce every few days, geth could go through these tar files and wherever a file gets close to reaching it's maximum allocation size (that 512 KB or whatever threshold/limit it's decided on), it could take the next file and move it to the end of the tar file and converting the freed space to padding for the file that gets close to its maximum allocated space.\r\n \r\n\r\n\r\n  \r\n\r\n\r\n",
  "closed_by": {
    "login": "adamschmideg",
    "id": 208822,
    "node_id": "MDQ6VXNlcjIwODgyMg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/208822?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/adamschmideg",
    "html_url": "https://github.com/adamschmideg",
    "followers_url": "https://api.github.com/users/adamschmideg/followers",
    "following_url": "https://api.github.com/users/adamschmideg/following{/other_user}",
    "gists_url": "https://api.github.com/users/adamschmideg/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/adamschmideg/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/adamschmideg/subscriptions",
    "organizations_url": "https://api.github.com/users/adamschmideg/orgs",
    "repos_url": "https://api.github.com/users/adamschmideg/repos",
    "events_url": "https://api.github.com/users/adamschmideg/events{/privacy}",
    "received_events_url": "https://api.github.com/users/adamschmideg/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352553637",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-352553637",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 352553637,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjU1MzYzNw==",
    "user": {
      "login": "mariushudea",
      "id": 34661103,
      "node_id": "MDQ6VXNlcjM0NjYxMTAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mariushudea",
      "html_url": "https://github.com/mariushudea",
      "followers_url": "https://api.github.com/users/mariushudea/followers",
      "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
      "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
      "organizations_url": "https://api.github.com/users/mariushudea/orgs",
      "repos_url": "https://api.github.com/users/mariushudea/repos",
      "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mariushudea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-18T20:50:30Z",
    "updated_at": "2017-12-18T20:50:30Z",
    "author_association": "NONE",
    "body": "Just noticed  #15643 in the issues list, same stuff I mention at the beginning of my post.\r\n\r\nHe suggests reducing the number of files, but that's not really necessary. Just moving them into folders and having less than a few thousand per folder would be enough. ",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352553637/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352679046",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-352679046",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 352679046,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjY3OTA0Ng==",
    "user": {
      "login": "karalabe",
      "id": 129561,
      "node_id": "MDQ6VXNlcjEyOTU2MQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/129561?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/karalabe",
      "html_url": "https://github.com/karalabe",
      "followers_url": "https://api.github.com/users/karalabe/followers",
      "following_url": "https://api.github.com/users/karalabe/following{/other_user}",
      "gists_url": "https://api.github.com/users/karalabe/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/karalabe/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/karalabe/subscriptions",
      "organizations_url": "https://api.github.com/users/karalabe/orgs",
      "repos_url": "https://api.github.com/users/karalabe/repos",
      "events_url": "https://api.github.com/users/karalabe/events{/privacy}",
      "received_events_url": "https://api.github.com/users/karalabe/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-19T08:53:57Z",
    "updated_at": "2017-12-19T08:53:57Z",
    "author_association": "MEMBER",
    "body": "Unfortunately this issue seems to stem from https://github.com/syndtr/goleveldb. I'm not sure what we can do ourselves, since we cannot change the storage engine of the database we use. One possible option that may be worth exploring is to change the files so that instead of using 2MB ones for each level, we use exponentially larger ones for deeper levels. \r\n\r\nE.g. 2MB for level 0, 4MB for level 1, ... \r\n\r\nI'm unsure though how this impacts compaction performance. If we can figure out a good enough way to benchmark it, I'm open to changing the layout to this model.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352679046/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352910780",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-352910780",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 352910780,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjkxMDc4MA==",
    "user": {
      "login": "mariushudea",
      "id": 34661103,
      "node_id": "MDQ6VXNlcjM0NjYxMTAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mariushudea",
      "html_url": "https://github.com/mariushudea",
      "followers_url": "https://api.github.com/users/mariushudea/followers",
      "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
      "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
      "organizations_url": "https://api.github.com/users/mariushudea/orgs",
      "repos_url": "https://api.github.com/users/mariushudea/repos",
      "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mariushudea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-19T22:49:31Z",
    "updated_at": "2017-12-19T22:49:31Z",
    "author_association": "NONE",
    "body": "> since we cannot change the storage engine of the database we use\r\n\r\nWhy would that be? Is it too difficult to implement another database? Isn't there some \"class\" or something in this project that would abstract the database and just have open database , get key/value , set key / value , close db?\r\n\r\nWould it be too hard for example to \"import\" that goleveldb project to this project and \"patch it\" within this project to implement this change in physical layout of the files on disk?  I would think it's just changing a few functions that handle file creating and access, nothing more.\r\n\r\nI'm sorry if I'm saying something stupid, I'm not familiar with how Go works, I mostly code in C# and PHP/Javascript so I can understand the Go code but I wouldn't dare to try to make changes to this code.\r\n\r\nBut I really believe the performance on mechanical hard drives at least on Windows machines is affected in a significant enough measure that it would be worth making this change. Even with solid state drives, I think Windows suffers (to a lesser degree) when trying to work with so many files in a single folder. \r\n\r\nOh that reminded me of something else. \r\n\r\nA lot of people nowadays use small SSDs (120  GB , 240 GB) for boot drives and they're basically 40-60 GB full with just the OS and some apps installed. \r\n\r\ngeth by default stores the chaindata in C:\\users\\[user]\\roaming something, so it goes on the boot drive by default, filling the small drive. \r\nIn addition to that, a lot of small 120 GB SSDs use TLC drives with only 30-40 TB of writes worth of endurance, and geth with its lots of small writes can go through a lot of that during it's life.  \r\nIt's not necessarily the quantity of data, but the small amounts of information written constantly to lots of files, forcing writing to different 512 byte \"sectors\" and eventually forcing erasing of \"pages\" (I think 128-512KB blocks made of of 512 sectors, as SSDs can't write over data on sectors and can't erase individual sectors in a block, the whole block must be erased and good data from sectors has to be moved somewhere else)\r\n\r\nNot many people are familiar enough with links to move the chaindata to other partitions and link to them transparently so.\r\n\r\nMaybe the installer for geth should have a \"run once after installation\" type of application which allows user to select a folder where this data is stored, and in an \"advanced\" tab maybe allow user to configure how much memory is geth allowed to use (because most users with 8-16GB of memory could perhaps allow more than the default which I think is 128MB and more memory could speed up sync or reduce disk i/o) and maybe how many connections can be made to other peers. \r\n\r\nMaybe add to get a command line option -fromFile / -loadconfiguration \"filename.cfg/ini/whatever\" if there isn't one and/or have geth by default load a \"default.cfg\" from same folder where it's located. \r\n\r\nMaybe this could help make geth run \"natively\" as a windows service instead of using wrappers or other things - as it runs it could monitor the configuration file and if there are changes it could adjust on the fly or restart to apply changes.\r\n \r\n ",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/352910780/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/353695187",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-353695187",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 353695187,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzY5NTE4Nw==",
    "user": {
      "login": "mtbitcoin",
      "id": 8327464,
      "node_id": "MDQ6VXNlcjgzMjc0NjQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/8327464?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mtbitcoin",
      "html_url": "https://github.com/mtbitcoin",
      "followers_url": "https://api.github.com/users/mtbitcoin/followers",
      "following_url": "https://api.github.com/users/mtbitcoin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mtbitcoin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mtbitcoin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mtbitcoin/subscriptions",
      "organizations_url": "https://api.github.com/users/mtbitcoin/orgs",
      "repos_url": "https://api.github.com/users/mtbitcoin/repos",
      "events_url": "https://api.github.com/users/mtbitcoin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mtbitcoin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-23T00:30:21Z",
    "updated_at": "2017-12-23T00:30:21Z",
    "author_association": "NONE",
    "body": "Would using a file fragmentation tool like contig.exe help?",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/353695187/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/353707368",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-353707368",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 353707368,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1MzcwNzM2OA==",
    "user": {
      "login": "mariushudea",
      "id": 34661103,
      "node_id": "MDQ6VXNlcjM0NjYxMTAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mariushudea",
      "html_url": "https://github.com/mariushudea",
      "followers_url": "https://api.github.com/users/mariushudea/followers",
      "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
      "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
      "organizations_url": "https://api.github.com/users/mariushudea/orgs",
      "repos_url": "https://api.github.com/users/mariushudea/repos",
      "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mariushudea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2017-12-23T05:02:08Z",
    "updated_at": "2017-12-23T05:03:43Z",
    "author_association": "NONE",
    "body": "It would be minimal, because you're defragmenting the files AFTER geth has done the damage, when you already have 50-70 GB on your hard drive and after it takes DAYS to reach the last block with a mechanical drive (SSDs can manage it in 6-10 hours). \r\nAnd when you run geth for the 2nd or 3rd time and the files start to be updated with new data, they start to become fragmented again.\r\nAnd you still have the huge number of files in one folder which slows down NTFS , like i said, ideally you want less than around 1000 files in each folder, otherwise you get slowdowns and higher access times.\r\n\r\nI had geth installed on my computer on my 120 GB SSD drive, and I had to use removedb yesterday to delete the 75 GB of data that accumulated because I was running out of disk space. I used --syncmode fast --cache 3072 and after using around 6GB of memory for 8 hours, it reached the last block and used only 45 GB of data.  But i'm not sure I'm gonna do it for much longer... to get that 45 GB of data, geth probably wrote around 55 GB on disk, and the endurance of this 120 GB SSD is only ~ 40 TB.  Not gonna do this remove and re-download every week just to have the full geth and kill my SSD prematurely.\r\n\r\nOn one of the dedicated servers I rent that came with 2 x 500 GB drives, I installed geth on the second unused 500 GB drive on the 18th of December and it's STILL importing data (currently at 4 373 000 state entries out of around 5 800 000) so it will probably still take 4-5 more days just to reach the last block because geth writes in 22000 files using ~ 41 GB in total. Looking with resource monitor, the disk queue length is pegged at 5 which is pretty much the maximum this 500 GB HDD can do and there's 700K - 1 MB/s worth of writes spread across 22k files - you get the OS updating its last modified counters, last access times for those 22k files, you get the nfts transaction log, master file table, backup master file table, bitmap table (free space table)  all being updated with every write... it's a mess.\r\n\r\nIt's a shame, because this dedicated server has very light work and would be ideal as a node to serve lightmode users and I've configured to serve up to 100 users in lightmode and it's probably not even working because it doesn't have all the chaindata downloaded.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/353707368/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/355744312",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-355744312",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 355744312,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NTc0NDMxMg==",
    "user": {
      "login": "mdealer",
      "id": 1102061,
      "node_id": "MDQ6VXNlcjExMDIwNjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1102061?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mdealer",
      "html_url": "https://github.com/mdealer",
      "followers_url": "https://api.github.com/users/mdealer/followers",
      "following_url": "https://api.github.com/users/mdealer/following{/other_user}",
      "gists_url": "https://api.github.com/users/mdealer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mdealer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mdealer/subscriptions",
      "organizations_url": "https://api.github.com/users/mdealer/orgs",
      "repos_url": "https://api.github.com/users/mdealer/repos",
      "events_url": "https://api.github.com/users/mdealer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mdealer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-06T12:37:40Z",
    "updated_at": "2018-01-06T12:38:03Z",
    "author_association": "NONE",
    "body": "Creating 25000 files in a single directory is why directories exist in the first place to allow splitting the stuff up. I'm not sure this is the only cause of my problem, but I've got a node that has 100% Disk usage all the time with 40-60MB/s random reading and writing. This is on a reasonable SSD. The node syncs like my grandma sprints... Something should be definitely done with the Disk I/O.\r\n  ",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/355744312/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356594389",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-356594389",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 356594389,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjU5NDM4OQ==",
    "user": {
      "login": "destenson",
      "id": 282538,
      "node_id": "MDQ6VXNlcjI4MjUzOA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/282538?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/destenson",
      "html_url": "https://github.com/destenson",
      "followers_url": "https://api.github.com/users/destenson/followers",
      "following_url": "https://api.github.com/users/destenson/following{/other_user}",
      "gists_url": "https://api.github.com/users/destenson/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/destenson/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/destenson/subscriptions",
      "organizations_url": "https://api.github.com/users/destenson/orgs",
      "repos_url": "https://api.github.com/users/destenson/repos",
      "events_url": "https://api.github.com/users/destenson/events{/privacy}",
      "received_events_url": "https://api.github.com/users/destenson/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-10T12:55:34Z",
    "updated_at": "2018-01-10T13:13:19Z",
    "author_association": "NONE",
    "body": "@mdealer, in my experience (and @mariushudea's) simply having more than approximately 1000 files in a single directory is enough to cause significant slowdown due to excessive disk I/O.\r\n\r\nIn #15643, I suggested reducing the number of files by increasing the size of each one. Another viable solution is to split them among several directories. But the tens of thousands of files are only 2.5MB in size. IMO, there's very little reason to keep them that small while it causes these issues.\r\n\r\nI imagine the root cause of this is inefficient, excessive, and unnecessary reads and writes of filesystem metadata as the directory is continuously scanned while creating, writing and manipulating these files.\r\n\r\nThis [in-depth article from Microsoft](https://technet.microsoft.com/en-us/library/cc781134(v=ws.10).aspx) about NTFS hints at a likely cause of the problem in a brief paragraph near the middle of the page:\r\n> If you have an NTFS volume with a high number of folders or files, and a program is running that briefly accesses each of these in turn, the I/O bandwidth used to generate the Last Access Time updates can be a significant percentage of the overall I/O bandwidth.\r\n\r\nMy chaindata directory has nearly 50000 files in it. I have geth syncing in the background and the chaindata directory opened in windows explorer. As I watch, geth has quickly maxed out the I/O channel on that hard drive, creating 2-3 files per second, and windows explorer is using 100% of 2 to 3 (of 8) cores just to keep up with all the changes. This tells me there is a *lot* of stuff going on with all these files being created & manipulated on the filesystem unnecessarily.\r\n\r\nThis issue has been one for a long time for a lot of people. I first tried to run a full node 2 years ago & it was a likely a major reason my laptop's hard drive failed within weeks of trying. It's now two years later, and it remains uncorrected.. I can't help but think this is almost too menial and boring a problem for the developers to consider fixing.\r\n\r\nI don't \"blame\" them, since they have much bigger, more interesting problems to solve than optimizing filesystem usage. But this a widely used product, and has had a notoriously bad user experience. They really should consider recruiting or hiring some other people who will fix these kinds of usability issues so we all don't have to continue dealing with such a troublesome and unnecessary problem.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356594389/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356604461",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-356604461",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 356604461,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjYwNDQ2MQ==",
    "user": {
      "login": "mariushudea",
      "id": 34661103,
      "node_id": "MDQ6VXNlcjM0NjYxMTAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mariushudea",
      "html_url": "https://github.com/mariushudea",
      "followers_url": "https://api.github.com/users/mariushudea/followers",
      "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
      "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
      "organizations_url": "https://api.github.com/users/mariushudea/orgs",
      "repos_url": "https://api.github.com/users/mariushudea/repos",
      "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mariushudea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-10T13:38:24Z",
    "updated_at": "2018-01-10T13:38:24Z",
    "author_association": "NONE",
    "body": "I have submitted a bug/feature request on goleveldb's issues tracker and received a reply from the author.\r\n\r\nHere's the thread  :  https://github.com/syndtr/goleveldb/issues/198\r\n\r\nHe suggests using the storage API to make an extension to handle the file locations and changing some of the default parameters to use bigger individual files. Also, he says compaction could be a big cause for slowdowns due to it running in a single thread.\r\n\r\nAfter taking an hour or so going through the code it seems it's not quite as easy because I think currently at load database, he's just using a \"read directory\" function to make a list of all files in the folder and then scan each file to read up the blocks and potentially repair broken files and so on. \r\n\r\nIf I understood how everything works, that function would have to be changed to go recursively through folders to pick up files spread out through the folder structure... but at the same time there probably should also be some backwards compatibility kept.\r\n\r\nIt may make more sense to just \"fork\" the goleveldb\" at the same time and use this occasion to change how data is physically stored on disk. For example, i don't understand how it makes sense to have the golevel signature (8 bytes) at the END of files instead of start, making it hard to pre-allocate disk space to files and reduce disk fragmentation... or how there's a lot of seeking involved in files to read various things that could be moved at the start of the file and read in one shot in memory (like an index in an AVI file)\r\n \r\nI'm sorry to say i have practically no experience with Go, i would have tried to submit something to goleveldb otherwise (at least something that could be enable at compiled time to tweak it for geth)\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356604461/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356657583",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-356657583",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 356657583,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1NjY1NzU4Mw==",
    "user": {
      "login": "karalabe",
      "id": 129561,
      "node_id": "MDQ6VXNlcjEyOTU2MQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/129561?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/karalabe",
      "html_url": "https://github.com/karalabe",
      "followers_url": "https://api.github.com/users/karalabe/followers",
      "following_url": "https://api.github.com/users/karalabe/following{/other_user}",
      "gists_url": "https://api.github.com/users/karalabe/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/karalabe/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/karalabe/subscriptions",
      "organizations_url": "https://api.github.com/users/karalabe/orgs",
      "repos_url": "https://api.github.com/users/karalabe/repos",
      "events_url": "https://api.github.com/users/karalabe/events{/privacy}",
      "received_events_url": "https://api.github.com/users/karalabe/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-10T16:32:45Z",
    "updated_at": "2018-01-10T16:32:45Z",
    "author_association": "MEMBER",
    "body": "I'm running some benchmarks currently to see how tuning the file sizes\naffect performance. Will post the results when they become available.\n\nOn Jan 10, 2018 15:38, \"mariushudea\" <notifications@github.com> wrote:\n\n> I have submitted a bug/feature request on goleveldb's issues tracker and\n> received a reply from the author.\n>\n> Here's the thread : syndtr/goleveldb#198\n> <https://github.com/syndtr/goleveldb/issues/198>\n>\n> He suggests using the storage API to make an extension to handle the file\n> locations and changing some of the default parameters to use bigger\n> individual files. Also, he says compaction could be a big cause for\n> slowdowns due to it running in a single thread.\n>\n> After taking an hour or so going through the code it seems it's not quite\n> as easy because I think currently at load database, he's just using a \"read\n> directory\" function to make a list of all files in the folder and then scan\n> each file to read up the blocks and potentially repair broken files and so\n> on.\n>\n> If I understood how everything works, that function would have to be\n> changed to go recursively through folders to pick up files spread out\n> through the folder structure... but at the same time there probably should\n> also be some backwards compatibility kept.\n>\n> It may make more sense to just \"fork\" the goleveldb\" at the same time and\n> use this occasion to change how data is physically stored on disk. For\n> example, i don't understand how it makes sense to have the golevel\n> signature (8 bytes) at the END of files instead of start, making it hard to\n> pre-allocate disk space to files and reduce disk fragmentation... or how\n> there's a lot of seeking involved in files to read various things that\n> could be moved at the start of the file and read in one shot in memory\n> (like an index in an AVI file)\n>\n> I'm sorry to say i have practically no experience with Go, i would have\n> tried to submit something to goleveldb otherwise (at least something that\n> could be enable at compiled time to tweak it for geth)\n>\n> â€”\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-356604461>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAH6GbbTogZHdeVgVHnohKVYxfrrYDJxks5tJL1SgaJpZM4RGC7V>\n> .\n>\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/356657583/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/359211520",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-359211520",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 359211520,
    "node_id": "MDEyOklzc3VlQ29tbWVudDM1OTIxMTUyMA==",
    "user": {
      "login": "mariushudea",
      "id": 34661103,
      "node_id": "MDQ6VXNlcjM0NjYxMTAz",
      "avatar_url": "https://avatars.githubusercontent.com/u/34661103?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mariushudea",
      "html_url": "https://github.com/mariushudea",
      "followers_url": "https://api.github.com/users/mariushudea/followers",
      "following_url": "https://api.github.com/users/mariushudea/following{/other_user}",
      "gists_url": "https://api.github.com/users/mariushudea/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mariushudea/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mariushudea/subscriptions",
      "organizations_url": "https://api.github.com/users/mariushudea/orgs",
      "repos_url": "https://api.github.com/users/mariushudea/repos",
      "events_url": "https://api.github.com/users/mariushudea/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mariushudea/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-01-20T23:52:55Z",
    "updated_at": "2018-01-20T23:52:55Z",
    "author_association": "NONE",
    "body": "Any update on those benchmarks ? \r\nApologies if I seem impatient. \r\n\r\nTo provide some minimal value, even though it's a bit unrelated to this: \r\n\r\nSince my last post I also made a sort of experiment, I installed Virtualbox and created a virtual machine with Windows 2008 R2 server and added 4 virtual hard drives to it, each on a separate physical hard drive on my machine.  Then, I created a software RAID 5 hard drive inside Windows 2008.\r\n\r\ngeth managed to download almost all the blocks and at most I got up to around 200ms of \"processing time\" to insert a bunch of records in the database, and outside the virtual machine each hdd got only up to around 0.5 at disk queue in Resource Monitor (compared to up to 5 at disk queue and up to 1.5-3 seconds when running geth from a single mechanical hard drive, once you go over around 30-50 GB of data) \r\n\r\nI had to use a trial version of Windows 2008 because it's not possible to create a software RAID 5 in Windows 7.\r\nAlso, the main problem is that at least the way I configured the virtual machine, i had a serious issue with time drift, the clock was out of control, going 7-15s out of sync every 10-15 minutes or so. Had to install a software to get the time from internet every 5 minutes and set the correct time.\r\nNever got it to sync completely though, in around 2-3 days, because geth still kept dropping peers, perhaps due to the clock being so screwed up. \r\n\r\ngeth also basically got stuck a couple of times for hours, not finding any peers or searching for other new peers - a simple Ctrl+C to close it and restarting it right away would find peers and geth would resume downloading blocks. ",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/359211520/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/441399412",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-441399412",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 441399412,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MTM5OTQxMg==",
    "user": {
      "login": "destenson",
      "id": 282538,
      "node_id": "MDQ6VXNlcjI4MjUzOA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/282538?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/destenson",
      "html_url": "https://github.com/destenson",
      "followers_url": "https://api.github.com/users/destenson/followers",
      "following_url": "https://api.github.com/users/destenson/following{/other_user}",
      "gists_url": "https://api.github.com/users/destenson/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/destenson/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/destenson/subscriptions",
      "organizations_url": "https://api.github.com/users/destenson/orgs",
      "repos_url": "https://api.github.com/users/destenson/repos",
      "events_url": "https://api.github.com/users/destenson/events{/privacy}",
      "received_events_url": "https://api.github.com/users/destenson/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-24T22:17:40Z",
    "updated_at": "2018-11-24T22:25:06Z",
    "author_association": "NONE",
    "body": "I made a fix to this & I am testing it now. It seems to be _dramatically_ faster.\r\n\r\nI am currently syncing the entire blockchain to an HDD and after an hour and a half, it's 25% done.\r\n\r\nI will submit a PR once I've verified that all works.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/441399412/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/525206205",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/15704#issuecomment-525206205",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/15704",
    "id": 525206205,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyNTIwNjIwNQ==",
    "user": {
      "login": "adamschmideg",
      "id": 208822,
      "node_id": "MDQ6VXNlcjIwODgyMg==",
      "avatar_url": "https://avatars.githubusercontent.com/u/208822?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/adamschmideg",
      "html_url": "https://github.com/adamschmideg",
      "followers_url": "https://api.github.com/users/adamschmideg/followers",
      "following_url": "https://api.github.com/users/adamschmideg/following{/other_user}",
      "gists_url": "https://api.github.com/users/adamschmideg/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/adamschmideg/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/adamschmideg/subscriptions",
      "organizations_url": "https://api.github.com/users/adamschmideg/orgs",
      "repos_url": "https://api.github.com/users/adamschmideg/repos",
      "events_url": "https://api.github.com/users/adamschmideg/events{/privacy}",
      "received_events_url": "https://api.github.com/users/adamschmideg/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-08-27T08:51:03Z",
    "updated_at": "2019-08-27T08:51:03Z",
    "author_association": "MEMBER",
    "body": "This is something  that should be changed in LevelDb upstream (sharding the files in folders on NTFS).",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/525206205/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
